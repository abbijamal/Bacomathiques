{"api":{"version":2,"latestVersion":2},"lesson":{"id":"chaines-markov","level":"terminale","title":"Chapitre XVI – Chaînes de Markov (Maths expertes)","chapter":16,"specialty":true,"content":"/api/v2/terminale/chaines-markov/","comments":"/api/v2/terminale/chaines-markov/comments/","summary":"/api/v2/terminale/chaines-markov/summary/"},"html":"<h2 id=\"graphe-pondere-et-graphe-probabiliste\">Graphe pondéré et graphe probabiliste</h2>\n<h3 id=\"definition\">Définition</h3>\n<div class=\"formula\">\n<h4>Graphe pondéré</h4>\n<p>Un graphe est dit <strong>pondéré</strong> si chacune de ses arêtes est affecté d’un nombre positif (ou nul) que l’on appelle <strong>poids</strong>.</p>\n<p>Le poids d’une chaîne (ou d’un chemin) est la somme des poids de ses arêtes.</p>\n</div>\n\n<div class=\"formula\">\n<h4>Graphe probabiliste</h4>\n<p>On appelle <strong>graphe probabiliste</strong> un graphe orienté et pondéré tel que :</p>\n<ul>\n<li><p>Pour chaque sommet, la somme des poids des arcs issus de ce sommet vaut <math>1</math>.</p></li>\n<li><p>Il y a au plus <math>1</math> arrête orientée reliant chaque sommet.</p></li>\n</ul>\n</div>\n<p>Il peut être utile de faire l’analogie entre les graphes probabilistes et <a href=\"https://bacomathiqu.es/cours/premiere/probabilites/#arbre-de-probabilit%C3%A9\">les arbres de probabilité</a> vus en classe de Première.</p>\n\n<h3 id=\"matrice-de-transition\">Matrice de transition</h3>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit <math>G</math> un graphe probabiliste d’ordre <math>n</math>. On appelle <strong>matrice de transition</strong> du graphe <math>G</math>, la matrice carrée d’ordre <math>n</math> dont le coefficient à la ligne <math>i</math> et à la colonne <math>j</math> est égal au poids de l’arête reliant le sommet <math>i</math> au sommet <math>j</math>.</p>\n<p>Une telle matrice est qualifiée de <strong>stochastique</strong> car la somme des coefficients de chacune de ses lignes vaut <math>1</math>.</p>\n</div>\n\n<p>Attention cependant à ne pas confondre matrice de transition et matrice d’adjacence.</p>\n<h2 id=\"chaines-de-markov\">Chaînes de Markov</h2>\n<h3 id=\"definition-1\">Définition</h3>\n<p>Il vous est fortement conseillé de relire (et de maîtriser) le cours sur <a href=\"https://bacomathiqu.es/cours/terminale/variables-aleatoires-concentration-grands-nombres/\">les variables aléatoires</a> avant d’aborder cette section. De plus, sachez que cette partie est sans doute la plus difficile du programme de Terminale. Mais ne vous découragez pas car elle reste parfaitement accessible !</p>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit <math>(X_n)</math> une suite de variables aléatoires discrètes définies sur un même univers <math>\\Omega</math> et à valeurs dans un ensemble <math>E</math>. On dit que <math>(X_n)</math> définit une <strong>chaîne de Markov</strong> sur <math>E</math> si pour tout <math>n \\in \\mathbb{N}</math> et tout <math>x_0, x_1, x_2, \\dots, x_n \\in E</math>, l’événement <math>(X_n = x_n)</math> ne dépend que de l’événement antérieur <math>(X_{n-1} = x_{n-1})</math> (et pas des précédents) ; autrement dit, si <math>P_{(X_{n-1} = x_{n-1}) \\, \\cap \\dots \\cap \\, (X_0 = x_0)}(X_n = x_n) = P_{(X_{n-1} = x_{n-1})}(X_n = x_n)</math>.</p>\n<p>De plus, l’ensemble <math>E</math> est appelé <strong>espace des états</strong> de la chaîne de Markov.</p>\n</div>\n<p>En français, cela signifie que si <math>X_n</math> représente l’état d’un système à un temps <math>n</math>, alors l’état suivant <math>X_{n+1}</math> ne dépend que de l’état au temps <math>n</math> et pas des états précédents.\nDe plus, notez bien que nous n’avons pas fait d’hypothèse sur le cardinal de <math>E</math> (qui peut donc être de cardinal <math>m \\in \\mathbb{N}</math>).</p>\n\n\n<div class=\"formula\">\n<h4>Chaîne de Markov homogène</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov dont on note <math>E</math> l’espace des états. Alors <math>(X_n)</math> est dite <strong>homogène</strong> si pour tout <math>n \\in \\mathbb{N}</math> et pour tout <math>x</math>, <math>y \\in E</math>, la probabilité <math>P_{(X_n = x)}(X_{n+1} = y)</math> est indépendante de <math>n</math>.</p>\n<p>En termes mathématiques, cela signifie que pour tout <math>n \\in \\mathbb{N}</math> et pour tout <math>x</math>, <math>y \\in E</math>, <math>P_{(X_n = x)}(X_{n+1} = y) = P_{(X_0 = x)}(X_1 = y)</math>.</p>\n</div>\n\n<h3 id=\"matrice-et-graphe-associes-a-une-chaine-de-markov\">Matrice et graphe associés à une chaîne de Markov</h3>\n<div class=\"formula\">\n<h4>Matrice de transition</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on note <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des états. La <strong>matrice de transition</strong> de <math>(X_n)</math> est la matrice carrée d’ordre <math>m</math> dont le coefficient situé à la <math>i</math>-ième ligne et à la <math>j</math>-ième colonne est égal à <math>p_{i,j} = P_{(X_n = x_i)}(X_{n+1} = x_j)</math>.</p>\n</div>\n\n<div class=\"formula\">\n<h4>Graphe associé à une chaîne de Markov</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on note <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des états. On associe à cette chaîne de Markov un graphe probabiliste <math>G</math> d’ordre <math>m</math> dont les sommets sont les états <math>x_i</math> et dont les arêtes <math>x_i - x_j</math> sont pondérées par les poids <math>p_{i,j} = P_{(X_n = x_i)}(X_{n+1} = x_j)</math>.</p>\n<p>La matrice de transition de <math>(X_n)</math> est égale à la matrice de transition du graphe probabiliste <math>G</math> : il s’agit donc aussi d’une matrice stochastique.</p>\n</div>\n\n<h3 id=\"distributions-dans-une-chaine-de-markov\">Distributions dans une chaîne de Markov</h3>\n<div class=\"formula\">\n<h4>Proposition</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on note <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des états. On pose <math>p_{i,j}^{(k)} = P_{(X_0 = x_i)}(X_k = x_j)</math> pour tout <math>k \\in \\mathbb{N}^*</math> (qui représente la probabilité que la chaîne de Markov <math>(X_n)</math> passe de l’état <math>x_i</math> à l’état <math>x_j</math> en <math>k</math> étapes). On a :\n</p><div class=\"katex-display\"><math displaystyle>p_{i,j}^{(k)} = \\sum_{q=1}^m p_{i,q}^{(k-1)} \\times p_{q,j}^{(1)} = p_{i,1}^{(k-1)} \\times p_{1,j}^{(1)} + p_{i,2}^{(k-1)} \\times p_{2,j}^{(1)} + \\dots + p_{i,m}^{(k-1)} \\times p_{m,j}^{(1)}</math></div>\nDe plus, comme <math>(X_n)</math> est homogène, <math>p_{i,j}^{(k)} = p_{i,j}^{(n+k)}</math> pour tout <math>n \\in \\mathbb{N}</math>.\n</div>\n\n<p>Cette formule semble un petit peu compliquée à interpréter. Elle signifie simplement que la probabilité que la chaîne de Markov <math>(X_n)</math> passe de l’état <math>x_i</math> à l’état <math>x_j</math> en <math>k</math> étapes est égale à la probabilité qu’elle passe de l’état <math>e_i</math> à <math>e_q</math> en une étape, puis de passer de <math>e_q</math> à <math>e_j</math> en <math>k-1</math> étapes. Heureusement, il est possible de la simplifier grandement à l’aide des matrices de transition.</p>\n<div class=\"formula\">\n<h4>Lien avec la matrice de transition</h4>\n<p>En reprenant les notations précédentes et en notant <math>M</math> la matrice de transition de <math>(X_n)</math>, alors <math>p_{i,j}^{(k)}</math> est le coefficient à la ligne <math>i</math> et à la colonne <math>j</math> de la matrice <math>M^k</math>.</p>\n</div>\n<p>Enfin, donnons la définition centrale de cette section.</p>\n<div data-api-v2-content-width=\"big\" class=\"formula\">\n<h4>Définition</h4>\n\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on note <math>E = \\{x_1, x_2, \\dots, x_m\\}</math> l’espace des états. On appelle <strong>suite des distributions</strong> de <math>(X_n)</math> la suite de matrices <math>(\\pi_n)</math>, définie pour tout <math>n \\in \\mathbb{N}</math> par <math>\\displaystyle{\\pi_n = \\begin{pmatrix} P(X_n = x_1) &amp; P(X_n = x_2) &amp; \\dots &amp; P(X_n = e_m) \\end{pmatrix}}</math>.</p>\n<p><math>\\pi_n</math> est donc une matrice ligne d’ordre <math>m</math> et est appelée <strong>distribution au temps <math>n</math></strong>.</p>\n<p><math>\\pi_0</math> (la distribution au temps <math>0</math>) est appelée <strong>distribution initiale</strong>.</p>\n</div>\n<p>Une propriété très sympathique des distributions, est que l’on dispose d’une relation de récurrence permettant de calculer facilement la distribution à un temps <math>n</math> donné.</p>\n<div class=\"formula\">\n<h4>Relation entre <math>\\pi_{n+1}</math> et <math>\\pi_n</math></h4>\n<p>En reprenant les notations de la définition précédente et en notant <math>M</math> la matrice de transition de <math>(X_n)</math>, alors la suite <math>(\\pi_n)</math> vérifie une relation de récurrence donnée pour tout <math>n \\in \\mathbb{N}</math> par <math>\\pi_{n+1} = \\pi_n M</math>.</p>\n<p>On en déduit que pour tout <math>n \\in \\mathbb{N}</math>, <math>\\pi_n = \\pi_0 M^n</math>.</p>\n</div>\n\n\n<h3 id=\"distribution-invariante\">Distribution invariante</h3>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène de matrice de transition <math>M</math>. Une distribution <math>\\pi</math> est <strong>invariante</strong> si les deux conditions suivantes sont respectées :</p>\n<ul>\n<li><p><math>\\displaystyle{\\pi M = \\pi}</math> (donc si <math>\\pi</math> est une distribution à un temps <math>n</math>, on a <math>\\pi = \\pi_n</math> et cette condition se résume à avoir <math>\\pi_n = \\pi_n M = \\pi_{n+1}</math>).</p></li>\n<li><p>La somme des coefficients de <math>\\pi</math> vaut <math>1</math>.</p></li>\n</ul>\n</div>\n<div class=\"formula\">\n<h4>Existence et unicité de la distribution invariante au temps <math>n</math></h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène de matrice de transition <math>M</math>.</p>\n<p>Si <math>M</math> ne possède aucun coefficient non nul autre que sur sa diagonale, alors <math>(X_n)</math> admet une unique distribution invariante <math>\\pi</math>.</p>\n</div>\n<div class=\"formula\">\n<h4>Convergence de la distribution</h4>\n<p>Soit <math>(X_n)</math> une chaîne de Markov homogène dont on note <math>(\\pi_n)</math> la suite des distributions.</p>\n<ul>\n<li><p>Si <math>(\\pi_n)</math> est une suite de matrices convergente, alors elle converge vers une distribution invariante <math>\\pi</math>.</p></li>\n<li><p>Si le cardinal de l’ensemble des états de <math>(X_n)</math> est <math>2</math>, alors <math>(\\pi_n)</math> est convergente (et converge vers la distribution invariante <math>\\pi</math>).</p></li>\n</ul>\n</div>\n\n"}