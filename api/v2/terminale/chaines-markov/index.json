{"api":{"version":2,"latestVersion":2},"lesson":{"id":"chaines-markov","level":"terminale","title":"Chapitre XVI – Chaînes de Markov (Maths expertes)","chapter":16,"specialty":true,"content":"/api/v2/terminale/chaines-markov/","comments":"/api/v2/terminale/chaines-markov/comments/","summary":"/api/v2/terminale/chaines-markov/summary/"},"difficulty":5,"pdf":"/pdf/lessons/terminale/chaines-markov.pdf","html":"<h2 id=\"graphe-pondéré-et-graphe-probabiliste\"><a href=\"#graphe-pond%C3%A9r%C3%A9-et-graphe-probabiliste\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Graphe pondéré et graphe probabiliste</h2>\n<h3 id=\"définition\"><a href=\"#d%C3%A9finition\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Définition</h3>\n<div class=\"formula\">\n<h4>Graphe pondéré</h4>\n<p>Un graphe est dit <strong>pondéré</strong> si chacune de ses arêtes est affecté d'un nombre positif (ou nul) que l'on appelle\n<strong>poids</strong>.</p>\n<p>Le poids d'une chaîne (ou d'un chemin) est la somme des poids de ses arêtes.</p>\n</div>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>On considère le graphe orienté et pondéré suivant :</p>\n<p><img src=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-1.svg\" alt=\"Graphe 1\"></p>\n<p>On a :</p>\n<ul>\n<li>Le poids de l'arête $A-B$ vaut $0$.</li>\n<li>Le poids du chemin $A-B-C-A-D$ vaut $0+4+2+7 = 13$.</li>\n</ul>\n</div>\n<div class=\"formula\">\n<h4>Graphe probabiliste</h4>\n<p>On appelle <strong>graphe probabiliste</strong> un graphe orienté et pondéré tel que :</p>\n<ul>\n<li>Pour chaque sommet, la somme des poids des arcs issus de ce sommet vaut $1$.</li>\n<li>Il y a au plus $1$ arrête orientée reliant chaque sommet.</li>\n</ul>\n</div>\n<p>Il peut être utile de faire l'analogie entre les graphes probabilistes\net <a href=\"/cours/premiere/probabilites/#2-arbre-de-probabilit%C3%A9\">les arbres de probabilité</a> vus en classe de Première.</p>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>Faisons un exemple concret. On souhaite étudier l'évolution d'une maladie chez un certain individu. À un jour donné, cet\nindividu est soit malade (que l'on note $M$), soit soigné (que l'on note $S$). On suppose que pour cette maladie :</p>\n<ul>\n<li>La probabilité qu'une personne malade guérisse le lendemain est $0,4$.</li>\n<li>La probabilité qu'une personne saine tombe malade le lendemain est $0,1$.</li>\n</ul>\n<p>Le graphe probabiliste modélisant cette situation est le graphe $G$ suivant :</p>\n<p><img src=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-2.svg\" alt=\"Graphe 2\"></p>\n<p>On remarque que la somme des poids des arêtes issues du sommet $S$ vaut $0,9+0,1 = 1$ (idem pour $M$ qui vaut $0,6+0,4 =\n1$).</p>\n</div>\n<h3 id=\"matrice-de-transition\"><a href=\"#matrice-de-transition\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Matrice de transition</h3>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit $G$ un graphe probabiliste d'ordre $n$. On appelle <strong>matrice de transition</strong> du graphe $G$, la matrice carrée\nd'ordre $n$ dont le coefficient à la ligne $i$ et à la colonne $j$ est égal au poids de l'arête reliant le sommet $i$ au\nsommet $j$.</p>\n<p>Une telle matrice est qualifiée de <strong>stochastique</strong> car la somme des coefficients de chacune de ses lignes vaut $1$.</p>\n</div>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>Dans l'exemple précédent (en supposant que $S$ est le 1<sup>er</sup> sommet et que $M$ est le 2<sup>ème</sup>) la matrice de transition du\ngraphe $G$ est $\\displaystyle{\\begin{pmatrix} 0,9 & 0,1 \\\\ 0,4 & 0,6 \\end{pmatrix}}$.</p>\n</div>\n<p>Attention cependant à ne pas confondre matrice de transition et matrice d'adjacence.</p>\n<h2 id=\"chaînes-de-markov\"><a href=\"#cha%C3%AEnes-de-markov\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Chaînes de Markov</h2>\n<h3 id=\"quest-ce-quune-chaîne-de-markov-\"><a href=\"#quest-ce-quune-cha%C3%AEne-de-markov-\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Qu'est-ce qu'une chaîne de Markov ?</h3>\n<p>Il vous est fortement conseillé de relire (et de maîtriser) le cours\nsur <a href=\"/cours/terminale/variables-aleatoires-concentration-grands-nombres/\">les variables aléatoires</a> avant d'aborder\ncette section. De plus, sachez que cette partie est sans doute la plus difficile du programme de Terminale. Mais ne vous\ndécouragez pas car elle reste parfaitement accessible !</p>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit $(X_n)$ une suite de variables aléatoires discrètes définies sur un même univers $\\Omega$ et à valeurs dans un\nensemble $E$. On dit que $(X_n)$ définit une <strong>chaîne de Markov</strong> sur $E$ si pour tout $n \\in \\mathbb{N}$ et tout $x_0,\nx_1, x_2, \\dots, x_n \\in E$, l'événement $(X_n = x_n)$ ne dépend que de l'événement antérieur $(X_{n-1} = x_{n-1})$ (et\npas des précédents) ; autrement dit, si $p_{(X_{n-1} = x_{n-1}) \\, \\cap \\dots \\cap \\, (X_0 = x_0)}(X_n = x_n) = p_{(X_\n{n-1} = x_{n-1})}(X_n = x_n)$.</p>\n<p>De plus, l'ensemble $E$ est appelé <strong>espace des états</strong> de la chaîne de Markov.</p>\n</div>\n<p>En français, cela signifie que si $X_n$ représente l'état d'un système à un temps $n$, alors l'état suivant $X_{n+1}$ ne\ndépend que de l'état au temps $n$ et pas des états précédents.</p>\n<p>De plus, notez bien que nous n'avons pas fait d'hypothèse sur le cardinal de $E$ (qui peut donc être de cardinal $m \\in\n\\mathbb{N}$). En classe de Terminale, nous nous limiterons principalement au cas où $E$ possède $2$ voire $3$ éléments,\nmais nous allons quand-même voir très bientôt un exemple de chaîne de Markov à $12$ états.</p>\n<div class=\"tip\">\n<h4>Variable aléatoire discrète</h4>\n<p>Une variable aléatoire $X$ définie sur un univers $\\Omega$ est dite <strong>discrète</strong> si $X(\\Omega)$ est un ensemble\ndénombrable.</p>\n</div>\n<div class=\"formula\">\n<h4>Chaîne de Markov homogène</h4>\n<p>Soit $(X_n)$ une chaîne de Markov dont on note $E$ l'espace des états. Alors $(X_n)$ est dite <strong>homogène</strong> si pour tout\n$n \\in \\mathbb{N}$ et pour tout $x$, $y \\in E$, la probabilité $p_{(X_n = x)}(X_{n+1} = y)$ est indépendante de $n$.</p>\n<p>En termes mathématiques, cela signifie que pour tout $n \\in \\mathbb{N}$ et pour tout $x$, $y \\in E$, $p_{(X_n = x)}(X_\n{n+1} = y) = p_{(X_0 = x)}(X_1 = y)$.</p>\n</div>\n<bubble variant=\"tip\" content-width=\"big\">\n<h4>Exemple</h4>\n<p>Eliott fait la collection des vignettes des 11 joueurs titulaires de l'Équipe de France de football qu'il trouve dans\ndes paquets de céréales. À chaque fois qu'il achète un paquet, il a donc une probabilité de $\\frac{1}{11}$ de tomber sur\nle $k$-ième joueur (pour tout $k$ compris entre $1$ et $11$).</p>\n<p>Si on note par $X_n$ le nombre de vignettes différentes dans la collection d'Eliott après qu'il eut ouvert $n$ paquets\nde céréales, on a que $(X_n)$ est une chaîne de Markov homogène (commençant par $X_0 = 0$). En effet, pour tout $k \\in\n\\{0, 1, \\dots, 11\\}$, on a que l'événement $(X_{n+1} = k)$ ne dépend que de $X_n$ :</p>\n<p>$\\displaystyle{p_{A}(X_{n+1} = k) = \\begin{cases} 1 \\text{ si } k = 11 \\text{ et si } A \\text{ est l'événement } (X_n =\n11) \\\\ \\frac{10}{11} \\text{ si } k \\neq 11 \\text{ et si } A \\text{ est l'événement } (X_n = k) \\\\ \\frac{1}{11} \\text{ si\n} A \\text{ est l'événement } (X_n = k-1) \\\\ 0 \\text{ sinon} \\end{cases}}$</p>\n<p>Pour détailler un peu plus :</p>\n<ul>\n<li>Si on a $(X_n = 11)$, alors Eliott a déjà sa collection complète. Donc la probabilité que sa collection reste complète\nest égale à $1$.</li>\n<li>Si on a $(X_n = k)$, alors la probabilité d'avoir $(X_{n+1} = k)$ est égale à la probabilité de ne pas tirer de\nnouveau joueur (qui est $1 - \\frac{1}{11} = \\frac{10}{11}$).</li>\n<li>Si on a $(X_n = k-1)$, alors la probabilité d'avoir $(X_{n+1} = k)$ est égale à la probabilité de tirer un nouveau\njoueur (qui est $\\frac{1}{11}$).</li>\n<li>Sinon, comme on ne peut pas tirer deux nouveaux joueurs d'un coup ou en enlever un de la collection, la probabilité\nd'avoir $(X_{n+1} = k)$ est égale à $0$.</li>\n<li>Notons de plus que $(X_n)$ est homogène car le calcul de $p(X_{n+1} = k)$ est indépendant de $n$ (mais reste dépendant\nde $X_n$, attention).</li>\n</ul>\n<p>De plus, on a que l'espace des états $E$ est $\\{0, 1, \\dots, 11\\}$.</p>\n<p>Cet exemple est très connu et porte un nom : il s'agit du <strong>problème du collectionneur de vignettes</strong>. Pour votre\nculture, sachez qu'en moyenne, il faudra ouvrir environ $n \\ln(n)$ paquets de céréales pour compléter une collection de\n$n$ vignettes.</p>\n</div>\n<h3 id=\"matrice-et-graphe-associés-à-une-chaîne-de-markov\"><a href=\"#matrice-et-graphe-associ%C3%A9s-%C3%A0-une-cha%C3%AEne-de-markov\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Matrice et graphe associés à une chaîne de Markov</h3>\n<div class=\"formula\">\n<h4>Matrice de transition</h4>\n<p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \\{x_1, x_2, \\dots, x_m\\}$ l'espace des états. La <strong>matrice\nde transition</strong> de $(X_n)$ est la matrice carrée d'ordre $m$ dont le coefficient situé à la $i$-ième ligne et à la\n$j$-ième colonne est égal à $p_{i,j} = p_{(X_n = x_i)}(X_{n+1} = x_j)$.</p>\n</div>\n<div class=\"tip\">\n<p>Comme cette probabilité est indépendante de $n$, on peut tout à fait prendre $n = 0$ dans la définition. On a alors $p_\n{i,j} = p_{(X_0 = x_i)}(X_1 = x_j)$.</p>\n</div>\n<div class=\"formula\">\n<h4>Graphe associé à une chaîne de Markov</h4>\n<p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \\{x_1, x_2, \\dots, x_m\\}$ l'espace des états. On associe à\ncette chaîne de Markov un graphe probabiliste $G$ d'ordre $m$ dont les sommets sont les états $x_i$ et dont les arêtes\n$x_i - x_j$ sont pondérées par les poids $p_{i,j} = p_{(X_n = x_i)}(X_{n+1} = x_j)$.</p>\n<p>La matrice de transition de $(X_n)$ est égale à la matrice de transition du graphe probabiliste $G$ : il s'agit donc\naussi d'une matrice stochastique.</p>\n</div>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>Reprenons l'exemple précédent. Alors la matrice de transition associée à $(X_n)$ est la matrice $M \\in \\mathcal{M}_{12}(\n\\mathbb{R})$ :</p>\n<p>$M = \\displaystyle{\\begin{pmatrix} \\frac{10}{11} & \\frac{1}{11} & 0 & \\dots & 0 & 0 \\\\ 0 & \\frac{10}{11} & \\frac{1}{11}\n& \\dots & 0 & 0 \\\\ \\vdots & \\vdots & \\vdots & \\ddots & \\vdots & \\vdots \\\\ 0 & 0 & 0 & \\dots & \\frac{10}{11} &\n\\frac{1}{11} \\\\ 0 & 0 & 0 & \\dots & 0 & 1 \\\\ \\end{pmatrix}}$</p>\n<p>Et le graphe associé à $(X_n)$ est le graphe probabiliste d'ordre $12$ :</p>\n<p><img src=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-3.svg\" alt=\"Graphe 3\"></p>\n</div>\n<h3 id=\"distributions-dans-une-chaîne-de-markov\"><a href=\"#distributions-dans-une-cha%C3%AEne-de-markov\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Distributions dans une chaîne de Markov</h3>\n<div class=\"formula\">\n<h4>Proposition</h4>\n<p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \\{x_1, x_2, \\dots, x_m\\}$ l'espace des états. On pose $p_\n{i,j}^{(k)} = p_{(X_0 = x_i)}(X_k = x_j)$ pour tout $k \\in \\mathbb{N}^\\*$ (qui représente la probabilité que la chaîne\nde Markov $(X_n)$ passe de l'état $x_i$ à l'état $x_j$ en $k$ étapes). On a :</p>\n<p>$\\displaystyle{p_{i,j}^{(k)} = \\sum_{q=1}^m p_{i,q}^{(k-1)} \\times p_{q,j}^{(1)} = p_{i,1}^{(k-1)} \\times p_{1,j}^{(1)}\n+ p_{i,2}^{(k-1)} \\times p_{2,j}^{(1)} + \\dots + p_{i,m}^{(k-1)} \\times p_{m,j}^{(1)}}$.</p>\n<p>De plus, comme $(X_n)$ est homogène, $p_{i,j}^{(k)} = p_{i,j}^{(n+k)}$ pour tout $n \\in \\mathbb{N}$.</p>\n</div>\n<div class=\"proof\">\n<h4>Proposition</h4>\n<p>$\\displaystyle{p_{i,j}^{(k)} = p_{(X_0 = x_i)}(X_k = x_j)}$</p>\n<p>$\\displaystyle{= \\sum_{q=1}^m p_{(X_0 = x_i)}((X_k = x_j) \\, \\cap \\, (X_{k-1} = x_q))}$</p>\n<p>$\\displaystyle{= \\sum_{q=1}^m p_{(X_{k-1} = x_q) \\, \\cap \\, (x_0 = x_i)}(X_k = x_j) p_{(X_0 = x_i)}(X_{k-1} = x_q)}$ (\npar la formule des probabilités totales)</p>\n<p>$\\displaystyle{= \\sum_{q=1}^m p_{(X_{k-1} = x_q)}(X_k = x_j) p_{(X_0 = x_i)}(X_{k-1} = x_q)}$</p>\n<p>$\\displaystyle{= \\sum_{q=1}^m p_{(X_0 = x_q)}(X_1 = x_j) p_{(X_0 = x_i)}(X_{k-1} = x_q)}$ (par homogénéité)</p>\n<p>$\\displaystyle{= \\sum_{q=1}^m p_{j,q}^{(1)} \\times p_{i,q}^{(k-1)}}$.</p>\n</div>\n<p>Cette formule semble un petit peu compliquée à interpréter. Elle signifie simplement que la probabilité que la chaîne de\nMarkov $(X_n)$ passe de l'état $x_i$ à l'état $x_j$ en $k$ étapes est égale à la probabilité qu'elle passe de l'état\n$e_i$ à $e_q$ en une étape, puis de passer de $e_q$ à $e_j$ en $k-1$ étapes. Heureusement, il est possible de la\nsimplifier grandement à l'aide des matrices de transition.</p>\n<div class=\"formula\">\n<h4>Lien avec la matrice de transition</h4>\n<p>En reprenant les notations précédentes et en notant $M$ la matrice de transition de $(X_n)$, on a que $p_{i,j}^{(k)}$\nest le coefficient à la ligne $i$ et à la colonne $j$ de la matrice $M^k$.</p>\n</div>\n<p>Enfin, donnons la définition centrale de cette section.</p>\n<bubble variant=\"formula\" content-width=\"big\">\n<h4>Définition</h4>\n<p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $E = \\{x_1, x_2, \\dots, x_m\\}$ l'espace des états. On appelle\n<strong>suite des distributions</strong> de $(X_n)$ la suite de matrices $(\\pi_n)$, définie pour tout $n \\in \\mathbb{N}$ par\n$\\displaystyle{\\pi_n = \\begin{pmatrix} p(X_n = x_1) & p(X_n = x_2) & \\dots & p(X_n = e_m) \\end{pmatrix}}$.</p>\n<p>$\\pi_n$ est donc une matrice ligne d'ordre $m$ et est appelée <strong>distribution au temps $n$</strong>.</p>\n<p>$\\pi_0$ (la distribution au temps $0$) est appelée <strong>distribution initiale</strong>.</p>\n</div>\n<p>Une propriété très sympathique des distributions, est que l'on dispose d'une relation de récurrence permettant de\ncalculer facilement la distribution à un temps $n$ donné.</p>\n<div class=\"formula\">\n<h4>Relation entre $\\pi_{n+1}$ et $\\pi_n$</h4>\n<p>En reprenant les notations de la définition précédente et en notant $M$ la matrice de transition de $(X_n)$, on a que la\nsuite $(\\pi_n)$ vérifie une relation de récurrence donnée pour tout $n \\in \\mathbb{N}$ par $\\pi_{n+1} = \\pi_n M$.</p>\n<p>On en déduit que pour tout $n \\in \\mathbb{N}$, $\\pi_n = \\pi_0 M^n$.</p>\n</div>\n<div class=\"proof\">\n<h4>Relation entre $\\pi_{n+1}$ et $\\pi_n$</h4>\n<p>Soit $n \\in \\mathbb{N}$. Les événements $(X_n = x_1), (X_n = x_2), \\dots, (X_n =x_m)$ partitionnent (recouvrent) notre\nunivers, donc par la formule des probabilités totales appliquée à notre système complet d'événements et à $(X_{n+1} =\nx_j)$ :</p>\n<p>$p(X_{n+1} = x_j) = p((X_{n+1} = x_j) \\, \\cap \\, (X_n = x_1)) + \\dots + p((X_{n+1} = x_j) \\, \\cap \\, (X_n = x_m))$</p>\n<p>$= p_{(X_n = x_1)}(X_{n+1} = x_j) \\times p(X_n = x_1) + \\dots + p_{(X_n = x_m)}(X_{n+1} = x_j) \\times (X_n = x_m)$</p>\n<p>$= \\pi_n M$</p>\n<p>Et la formule $\\pi_n = \\pi_0 M^n$ se déduit de la formule d'une suite géométrique (où $M$ serait la raison et $\\pi_0$ le\npremier terme).</p>\n</div>\n<div class=\"tip\">\n<h4>Exemple</h4>\n<p>Intéressons-nous à l'alimentation d'un chat durant la journée. Il dispose de trois gamelles différentes $L$, $C$ et $P$\ndans lesquelles se trouvent respectivement du lait, des croquettes et de la pâté.</p>\n<p>On suppose que le chat a commencé sa journée par du lait et que toutes les heures, il se dirige vers une des gamelles\nsuivant le graphe probabiliste ci-dessous :</p>\n<p><img src=\"https://bacomathiqu.es/img/lessons/terminale/chaines-markov/graphe-4.svg\" alt=\"Graphe 4\"></p>\n<p>On note par $X_n$ la variable aléatoire qui donne la gamelle qu'a choisi le chat à la $n$-ième heure. On a donc que $(\nX_n)$ est une chaîne de Markov homogène dont l'espace des états est $E = \\{L; C; P\\}$. Si on note $(\\pi_n)$ la suite des\ndistributions de $(X_n)$, on a alors que $\\pi_0 = \\begin{pmatrix} 1 & 0 & 0 \\end{pmatrix}$.</p>\n<p>Soit $M$ la matrice de transition $M$ de $(X_n)$. Calculons quelques puissances de $M$ :</p>\n<ul>\n<li>$\\displaystyle{M = \\begin{pmatrix} 0,5 & 0,3 & 0,2 \\\\ 0,2 & 0,7 & 0,1 \\\\ 0,3 & 0,3 & 0,4 \\end{pmatrix}}$</li>\n<li>$\\displaystyle{M^2 = \\begin{pmatrix} 0,37 & 0,42 & 0,21 \\\\ 0,27 & 0,58 & 0,15 \\\\ 0,33 & 0,42 & 0,25 \\end{pmatrix}}$</li>\n<li>$\\displaystyle{M^3 = \\begin{pmatrix} 0,332 & 0,468 & 0,2 \\\\ 0,296 & 0,532 & 0,172 \\\\ 0,324 & 0,468 & 0,208\n  \\end{pmatrix}}$</li>\n</ul>\n<p>Ainsi :</p>\n<ul>\n<li>$\\pi_1 = \\pi_0 M = \\begin{pmatrix} 0,5 & 0,3 & 0,2 \\end{pmatrix}$</li>\n<li>$\\pi_2 = \\pi_0 M^2 = \\begin{pmatrix} 0,37 & 0,42 & 0,21 \\end{pmatrix}$</li>\n<li>$\\pi_3 = \\pi_0 M^3 = \\begin{pmatrix} 0,332 & 0,468 & 0,2 \\end{pmatrix}$</li>\n</ul>\n<p>Et par exemple $p_{1,2}^{(3)} = 0,468$ : la probabilité que le chat passe à sa gamelle de croquettes 3 heures après le\nlait est d'environ 47 %.</p>\n</div>\n<h3 id=\"distribution-invariante\"><a href=\"#distribution-invariante\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Distribution invariante</h3>\n<div class=\"formula\">\n<h4>Définition</h4>\n<p>Soit $(X_n)$ une chaîne de Markov homogène de matrice de transition $M$. Une distribution $\\pi$ est <strong>invariante</strong> si\nles deux conditions suivantes sont respectées :</p>\n<ul>\n<li>$\\displaystyle{\\pi M = \\pi}$ (donc si $\\pi$ est une distribution à un temps $n$, on a $\\pi = \\pi_n$ et cette condition\nse résume à avoir $\\pi_n = \\pi_n M = \\pi_{n+1}$).</li>\n<li>La somme des coefficients de $\\pi$ vaut $1$.</li>\n</ul>\n</div>\n<div class=\"formula\">\n<h4>Existence et unicité de la distribution invariante au temps $n$</h4>\n<p>Soit $(X_n)$ une chaîne de Markov homogène de matrice de transition $M$.</p>\n<p>Si $M$ ne possède aucun coefficient non nul autre que sur sa diagonale, alors $(X_n)$ admet une unique distribution\ninvariante $\\pi$.</p>\n</div>\n<div class=\"formula\">\n<h4>Convergence de la distribution</h4>\n<p>Soit $(X_n)$ une chaîne de Markov homogène dont on note $(\\pi_n)$ la suite des distributions.</p>\n<ul>\n<li>Si $(\\pi_n)$ est une suite de matrices convergente, alors elle converge vers une distribution invariante $\\pi$.</li>\n<li>Si le cardinal de l'ensemble des états de $(X_n)$ est $2$, alors $(\\pi_n)$ est convergente (et converge vers la\ndistribution invariante $\\pi$).</li>\n</ul>\n</div>\n<bubble variant=\"tip\" content-width=\"big\">\n<h4>Exemple</h4>\n<p>Reprenons l'exemple précédent et voyons si $(X_n)$ admet une distribution invariante.</p>\n<p>Remarquons tout d'abord que la matrice de transition $M$ ne possède aucun coefficient non nul. Donc $(X_n)$ admet une\nunique distribution invariante $\\pi$.</p>\n<p>Posons donc $\\pi = \\begin{pmatrix} x & y & z \\end{pmatrix}$ et déterminons $x$, $y$ et $z$ :</p>\n<p>On doit avoir $\\pi M = \\pi$</p>\n<p>$\\iff \\begin{pmatrix} x & y & z \\end{pmatrix} \\begin{pmatrix} 0,5 & 0,3 & 0,2 \\\\ 0,2 & 0,7 & 0,1 \\\\ 0,3 & 0,3 & 0,4\n\\end{pmatrix} = \\begin{pmatrix} x & y & z \\end{pmatrix}$</p>\n<p>$\\iff \\begin{pmatrix} 0,5x + 0,2y + 0,3z & 0,3x + 0,7y + 0,3z & 0,2x + 0,1y + 0,4z \\end{pmatrix} = \\begin{pmatrix} x & y\n& z \\end{pmatrix}$</p>\n<p>$\\iff \\begin{cases} \\frac{1}{2}x + \\frac{1}{5}y + \\frac{3}{10}z = x \\\\ \\frac{3}{10}x + \\frac{7}{10}y + \\frac{3}{10}z = y\n\\\\ \\frac{1}{5}x + \\frac{1}{10}y + \\frac{2}{5}z = z \\end{cases}$ (en passant en écriture fractionnaire)</p>\n<p>$\\iff \\begin{cases} -\\frac{1}{2}x + \\frac{1}{5}y + \\frac{3}{10}z = 0 \\\\ \\frac{3}{10}x - \\frac{3}{10}y + \\frac{3}{10}z =\n0 \\\\ \\frac{1}{5}x + \\frac{1}{10}y - \\frac{3}{5}z = 0 \\end{cases}$</p>\n<p>$\\iff \\begin{cases} x = \\frac{2}{5}y + \\frac{3}{5}z \\\\ -\\frac{9}{50}y + \\frac{12}{25}z = 0 \\\\ \\frac{9}{50}y -\n\\frac{12}{25}z = 0 \\end{cases}$</p>\n<p>$\\iff \\begin{cases} x = \\frac{2}{5} \\times \\frac{8}{3} z + \\frac{3}{5}z = \\frac{5}{3}z \\\\ y = \\frac{50}{9} \\times\n\\frac{12}{25}z = \\frac{8}{3}z \\end{cases}$</p>\n<p>Donc $\\pi$ est de la forme $\\pi = \\begin{pmatrix} \\frac{5}{3}z & \\frac{8}{3}z & z \\end{pmatrix}$. De plus, la somme des\ncoefficients de $\\pi$ doit faire $1$, donc :</p>\n<p>$\\frac{5}{3}z + \\frac{8}{3}z + z = 1 \\iff \\frac{16}{3}z = 1 \\iff z = \\frac{3}{16}$.</p>\n<p>Donc l'unique distribution invariante $\\pi$ de $(X_n)$ est $\\pi = \\begin{pmatrix} \\frac{5}{16} & \\frac{1}{2} &\n\\frac{3}{16} \\end{pmatrix} = \\begin{pmatrix} 0,3125 & 0,5 & 0,1875 \\end{pmatrix}$.</p>\n</div>\n","annals":[],"e3c":[]}