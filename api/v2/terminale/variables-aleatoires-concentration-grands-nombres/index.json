{"api":{"version":2,"latestVersion":2},"lesson":{"id":"variables-aleatoires-concentration-grands-nombres","level":"terminale","title":"Chapitre XI –  Variables aléatoires, concentration et loi des grands nombres","chapter":11,"specialty":false,"content":"/api/v2/terminale/variables-aleatoires-concentration-grands-nombres/","comments":"/api/v2/terminale/variables-aleatoires-concentration-grands-nombres/comments/","summary":"/api/v2/terminale/variables-aleatoires-concentration-grands-nombres/summary/"},"difficulty":5,"pdf":"pdf/cours/terminale/variables-aleatoires-concentration-grands-nombres//pdf/lessons/terminale/variables-aleatoires-concentration-grands-nombres.pdf.pdf","html":"<h2 id=\"somme-de-deux-variables-aléatoires\"><a href=\"#somme-de-deux-variables-al%C3%A9atoires\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Somme de deux variables aléatoires</h2>\n<h3 id=\"définition\"><a href=\"#d%C3%A9finition\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Définition</h3>\n<p>Il arrive que, on ne puisse pas modéliser une situation donnée à l'aide d'une seule variable aléatoire simple. C'est\npourquoi il est parfois utile d'en additionner plusieurs ou bien d'en multiplier par un réel.</p>\n<div class=\"formula\">\n<h4 id=\"définition-1\"><a href=\"#d%C3%A9finition-1\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Définition</h4>\n<p>Soient $X$ et $Y$ deux variables aléatoires définies sur un univers $\\Omega$ et soit $\\lambda$ un réel. On définit :</p>\n<ul>\n<li>$X + Y$ la variable aléatoire somme de $X$ et $Y$ définie pour tout $\\omega \\in \\Omega$ par $(X + Y)(\\omega) = X(\n  \\omega) + Y(\\omega)$.</li>\n<li>$\\lambda X$ la variable aléatoire produit de $\\lambda$ et $X$ définie pour tout $\\omega \\in \\Omega$ par $(\\lambda X)(\n  \\omega) = \\lambda X(\\omega)$.</li>\n</ul>\n</div>\n<div class=\"tip\">\n<h4 id=\"exemple\"><a href=\"#exemple\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Exemple</h4>\n<p>Encore une fois, il s'agit d'une définition un peu compliquée. Illustrons ceci par un exemple.</p>\n<p>On lance deux dés différents, équilibrés, et numérotés de $1$ à $6$. On note par $X$ la variable aléatoire donnant le\nrésultat sur lequel tombe le premier dé, et par $Y$ la variable aléatoire donnant le résultat sur lequel tombe le second\ndé.</p>\n<p>Dans cette situation, la variable aléatoire somme $X + Y$ donne la somme obtenue en additionnant le nombre sur lequel le\npremier dé est tombé avec celui sur lequel le deuxième dé est tombé.</p>\n</div>\n<h3 id=\"espérance-variance-et-écart-type\"><a href=\"#esp%C3%A9rance-variance-et-%C3%A9cart-type\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Espérance, variance et écart-type</h3>\n<p>Une somme de variable aléatoire reste une variable aléatoire. Donc il est tout à fait possible de calculer l'espérance,\nla variance, l'écart-type, ... d'une somme de variables aléatoires.</p>\n<p>Voyons dans un premier temps une propriété de l'espérance permettant de calculer plus facilement l'espérance d'une\ncombinaison linéaire de variables aléatoires.</p>\n<div class=\"formula\">\n<h4 id=\"linéarité-de-lespérance\"><a href=\"#lin%C3%A9arit%C3%A9-de-lesp%C3%A9rance\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Linéarité de l'espérance</h4>\n<p>Soient $X$ et $Y$ deux variables aléatoires définies sur un univers $\\Omega$ et soit $\\lambda$ un réel. Alors :</p>\n<ul>\n<li>$E(X + Y) = E(X) + E(Y)$.</li>\n<li>$E(\\lambda X) = \\lambda E(X)$.</li>\n</ul>\n</div>\n<div class=\"tip\">\n<h4 id=\"applications\"><a href=\"#applications\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Applications</h4>\n<p>Appliquons la première formule à l'exemple de la partie précédente.</p>\n<p>On a $E(X) = E(Y) = 1 \\times \\frac{1}{6} + 2 \\times \\frac{1}{6} + 3 \\times \\frac{1}{6} + 4 \\times \\frac{1}{6} + 5 \\times\n\\frac{1}{6} + 6 \\times \\frac{1}{6} = 3,5$.</p>\n<p>Donc $E(X+Y) = E(X) + E(Y) = 3,5 + 3,5 = 7$.</p>\n<p>En termes d'interprétation, cela signifie qu'en moyenne, sur un grand nombre de lancers, la somme obtenue lorsque l'on\nadditionne le résultat des deux dés vaut $7$.</p>\n</div>\n<p>Voyons désormais des formules permettant de calculer la variance et l'écart-type d'une combinaison linéaire de variables\naléatoires.</p>\n<div class=\"formula\">\n<h4 id=\"variance-et-écart-type\"><a href=\"#variance-et-%C3%A9cart-type\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Variance et écart-type</h4>\n<p>Soient $X$ et $Y$ deux variables aléatoires définies sur un univers $\\Omega$ et soit $\\lambda$ un réel. Alors :</p>\n<ul>\n<li>$V(X + Y) = V(X) + V(Y)$ si $X$ et $Y$ sont indépendantes (c'est-à-dire si le résultat de l'une n'a pas d'incidence\nsur le résultat de l'autre).</li>\n<li>$V(\\lambda X) = \\lambda^2 V(X)$.</li>\n<li>$\\sigma(\\lambda X) = \\sqrt{\\lambda^2} \\sigma(X)$.</li>\n</ul>\n</div>\n<h2 id=\"somme-de-plusieurs-variables-aléatoires\"><a href=\"#somme-de-plusieurs-variables-al%C3%A9atoires\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Somme de plusieurs variables aléatoires</h2>\n<h3 id=\"définition-et-propriétés\"><a href=\"#d%C3%A9finition-et-propri%C3%A9t%C3%A9s\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Définition et propriétés</h3>\n<p>Nous allons tenter de généraliser un petit peu le concept vu dans la section précédente. En effet, au lieu d'étudier la\nsomme de deux variables aléatoires, on va étudier la somme de $n$ variables aléatoires.</p>\n<p>En classe de Terminale, on se limite au cas où ces variables aléatoires suivent une même loi.</p>\n<div class=\"formula\">\n<h4 id=\"échantillon-aléatoire\"><a href=\"#%C3%A9chantillon-al%C3%A9atoire\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Échantillon aléatoire</h4>\n<p>Un $n$-uplet de variables aléatoires $(X_1, X_2, \\dots, X_n)$ qui sont toutes indépendantes et qui suivent une même loi\nde probabilité est appelé <strong>échantillon aléatoire de taille $n$ associé à cette loi</strong>.</p>\n</div>\n<div class=\"formula\">\n<h4 id=\"espérance-de-variables-aléatoires-de-même-loi\"><a href=\"#esp%C3%A9rance-de-variables-al%C3%A9atoires-de-m%C3%AAme-loi\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Espérance de variables aléatoires de même loi</h4>\n<p>Soit $(X_1, X_2, \\dots, X_n)$ un échantillon aléatoire de taille $n$. On pose $S_n = X_1 + X_2 + \\dots + X_n$ et $M_n =\n\\frac{S_n}{n}$. Alors :</p>\n<ul>\n<li>$E(S_n) = nE(X_1)$ et $V(S_n) = nV(X_1)$.</li>\n<li>$E(M_n) = E\\left(\\frac{S_n}{n}\\right) = \\frac{E(S_n)}{n} = E(X_1)$ et $V(M_n) = \\frac{V(S_n)}{n^2} = \\frac{V(X_1)\n  }{n}$.</li>\n</ul>\n</div>\n<div class=\"tip\">\n<h4 id=\"note\"><a href=\"#note\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Note</h4>\n<p>Petite note sur le nom des variables aléatoires précédentes :</p>\n<ul>\n<li>$S_n$ est la <strong>somme</strong> des $n$ variables aléatoires.</li>\n<li>$M_n$ est la <strong>moyenne empirique</strong> des $n$ variables aléatoires.</li>\n</ul>\n</div>\n<h3 id=\"somme--décompositions-de-certaines-variables-aléatoires\"><a href=\"#somme--d%C3%A9compositions-de-certaines-variables-al%C3%A9atoires\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Somme / décompositions de certaines variables aléatoires</h3>\n<p>Nous allons maintenant énoncer une propriété utile qui permet de trouver la loi suivie par une somme de variables\naléatoires indépendantes suivant une loi de Bernoulli.</p>\n<div class=\"formula\">\n<h4 id=\"somme-de-variables-aléatoires-indépendantes-suivant-une-même-loi-de-bernoulli\"><a href=\"#somme-de-variables-al%C3%A9atoires-ind%C3%A9pendantes-suivant-une-m%C3%AAme-loi-de-bernoulli\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Somme de variables aléatoires indépendantes suivant une même loi de Bernoulli</h4>\n<p>Soit $(X_1, X_2, \\dots, X_n)$ un échantillon aléatoire de taille $n$ associé à une loi de Bernoulli de paramètre $p$.</p>\n<p>Alors $X_1 + X_2 + \\dots + X_n$ suit une loi binomiale $\\mathcal{B}(n; p)$.</p>\n</div>\n<div class=\"tip\">\n<h4 id=\"exemple-1\"><a href=\"#exemple-1\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Exemple</h4>\n<p>On lance en même temps deux pièces équilibrées en l'air. On suppose qu'un succès est représenté par Pile.</p>\n<p>On modélise le résultat de la première par une variable aléatoire $X$ qui suit une loi de Bernoulli $\\mathcal{B}(0,5)$.\nDe même, on modélise le résultat de la seconde par une variable aléatoire $Y$ suivant la même loi que $X$.</p>\n<p>Alors $X + Y$ (qui modélise le nombre de Pile obtenus au total par les deux pièces) suit une loi binomiale $\\mathcal{B}(\n2; 0,5)$.</p>\n</div>\n<p>Enfin, signalons qu'il existe une réciproque de la première propriété qui permet de transformer une variable aléatoire\nsuivant une loi binomiale en somme de variables aléatoires suivant une loi de Bernoulli.</p>\n<div class=\"formula\">\n<h4 id=\"décomposition-dune-variable-aléatoire-suivant-une-loi-binomiale\"><a href=\"#d%C3%A9composition-dune-variable-al%C3%A9atoire-suivant-une-loi-binomiale\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Décomposition d'une variable aléatoire suivant une loi binomiale</h4>\n<p>Soit $X$ une variable aléatoire suivant une loi binomiale $\\mathcal{B}(n; p)$.</p>\n<p>Alors il existe $n$ variables aléatoires indépendantes $X_1$, $X_2$, ... , $X_n$ suivant toutes une loi de Bernoulli\n$\\mathcal{B}(p)$, et telles que $X = X_1 + X_2 + \\dots + X_n$.</p>\n</div>\n<div class=\"tip\">\n<h4 id=\"exemple-2\"><a href=\"#exemple-2\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Exemple</h4>\n<p>Soit $X$ suivant une loi binomiale $\\mathcal{B}\\left(3; \\frac{1}{6}\\right)$. Alors par la propriété précédente, il\nexiste $X_1$, $X_2$ et $X_3$, indépendantes et suivant une loi $\\mathcal{B}\\left(\\frac{1}{6}\\right)$ telles que\n$X = X_1 + X_2 + X_3$.</p>\n</div>\n<h2 id=\"concentration-et-loi-des-grands-nombres\"><a href=\"#concentration-et-loi-des-grands-nombres\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Concentration et loi des grands nombres</h2>\n<h3 id=\"inégalité-de-bienaymé-tchebychev\"><a href=\"#in%C3%A9galit%C3%A9-de-bienaym%C3%A9-tchebychev\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Inégalité de Bienaymé-Tchebychev</h3>\n<div class=\"formula\">\n<h4 id=\"inégalité-de-bienaymé-tchebychev-1\"><a href=\"#in%C3%A9galit%C3%A9-de-bienaym%C3%A9-tchebychev-1\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Inégalité de Bienaymé-Tchebychev</h4>\n<p>Soit $X$ une variable aléatoire d'espérance $E(X) = \\mu$ et de variance $V(X) = V$. Alors pour tout réel strictement\npositif $\\delta$, $p(|X-\\mu| \\geq \\delta) \\leq \\frac{V}{\\delta^2}$.</p>\n</div>\n<div class=\"tip\">\n<h4 id=\"autre-formulation\"><a href=\"#autre-formulation\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Autre formulation</h4>\n<p>Une autre formulation de cette inégalité est la suivante : $p(X \\notin ]\\mu - \\delta; \\mu + \\delta[) \\leq \\frac{V(X)\n}{\\delta^2}$.</p>\n</div>\n<p>Cette inégalité est un peu abstraite, donnons tout de suite un exemple.</p>\n<div class=\"tip\">\n<h4 id=\"exemple-3\"><a href=\"#exemple-3\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Exemple</h4>\n<p>Le poids moyen d'un bébé en kilogrammes à la naissance peut être modélisé par une variable aléatoire $X$ d'espérance\n$\\mu = 3,3$ et de variance $V = 0,25$.</p>\n<p>Un bébé est considéré de poids normal si son poids est compris entre $2,4$ et $4,2$ kilogrammes. Nous allons calculer une\nmajoration pour la probabilité qu'un bébé ne soit pas de poids normal à la naissance (c'est-à-dire, si $X \\notin ]3,3 -\n0,9; 3,3 + 0,9[$ ou encore si $|X - 3,3| \\geq 0,9$).</p>\n<p>On a $p(|X - 3,3| \\geq 0,9) \\leq \\frac{0,25}{0,9^2} \\approx 0,3086$ par l'inégalité de Bienaymé-Tchebychev.</p>\n<p>La probabilité qu'un bébé ne soit pas de poids normal à la naissance ne dépasse pas $0,3086$.</p>\n<p>Cette majoration n'est pas très satisfaisante, mais cela vient principalement du fait que la variance est trop élevée.</p>\n</div>\n<h3 id=\"inégalité-de-concentration\"><a href=\"#in%C3%A9galit%C3%A9-de-concentration\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Inégalité de concentration</h3>\n<div class=\"formula\">\n<h4 id=\"inégalité-de-concentration-1\"><a href=\"#in%C3%A9galit%C3%A9-de-concentration-1\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Inégalité de concentration</h4>\n<p>Soit $(X_1, X_2, \\dots, X_n)$ un échantillon aléatoire de taille $n$ associé à une loi d'espérance $\\mu$ et de variance\n$V$. On pose $M_n = \\frac{X_1 + X_2 + \\dots + X_n}{n}$, la moyenne empirique de cet échantillon.</p>\n<p>Alors pour tout réel strictement positif $\\delta$, $p(|M_n - \\mu| \\geq \\delta) \\leq \\frac{V}{n \\delta^2}$.</p>\n</div>\n<h3 id=\"loi-des-grands-nombres\"><a href=\"#loi-des-grands-nombres\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Loi des grands nombres</h3>\n<div class=\"formula\">\n<h4 id=\"loi-faible-des-grands-nombres\"><a href=\"#loi-faible-des-grands-nombres\" aria-hidden=\"true\" tabindex=\"-1\"><span class=\"icon icon-link\"></span></a>Loi faible des grands nombres</h4>\n<p>Soit $(X_1, X_2, \\dots, X_n)$ un échantillon aléatoire de taille $n$ associé à une loi d'espérance $\\mu$ et de variance\n$V$. On pose $M_n = \\frac{X_1 + X_2 + \\dots + X_n}{n}$, la moyenne empirique de cet échantillon.</p>\n<p>Alors pour tout réel strictement positif $\\delta$, $\\lim_{n \\rightarrow +\\infty} p(|M_n - \\mu| \\geq \\delta) = 0$.</p>\n</div>\n<div class=\"tip\">\n<p>Ce théorème signifie que la moyenne de l'échantillon se rapproche des moyennes des variables aléatoires quand la taille\nde l'échantillon augmente.</p>\n<p>Prenons l'exemple d'une maternité au 1<sup>er</sup> janvier et supposons que le premier-né soit un garçon. Il est tout à fait\npossible que le deuxième bébé soit également un garçon, alors que, statistiquement, on aurait pu s'attendre à une fille.</p>\n<p>Mais l'année peut très bien commencer par une dizaine de naissances de garçons à la suite !</p>\n<p>Cependant, si on fait un nouveau point au 31 décembre, on va se rendre compte, qu'effectivement, il y a eu environ 50 %\nde naissances de garçons et 50 % de naissances de filles. Il s'agit là d'un cas d'application de la loi des grands\nnombres.</p>\n</div>\n","annals":[],"e3c":[]}